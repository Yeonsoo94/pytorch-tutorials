{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using Pytorch\n",
    "\n",
    "\n",
    "1. Reading the input image\n",
    " - Performing transformations on the image, for example resize, center crop, normalization, etc.\n",
    "2. Forward Pass: Use the weights to predict the output. \n",
    "3. Based on the scores obtained, display the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "we can initialize the data transforms, image datasets, and the dataloaders.\n",
    "\n",
    "If you use models with the hard-coded normalization values, you should specify image transformations.\n",
    "\n",
    "Torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "batchSize = 16\n",
    "inputSize = 32 # 299 for VGG, 32 for CNN \n",
    "transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(inputSize),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Convolution Neural Network\n",
    "---------\n",
    "Define the neural network that has some learnable parameters (or weights).\n",
    "You can modify it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model\n",
    "---------\n",
    "\n",
    "The train_model function handles the training and validation of a given model. \n",
    "\n",
    "It takes a PyTorch model, a dictionary of dataloaders, a loss function, an optimizer, a specified number of epochs to train and validate. \n",
    "\n",
    "we need to find out the index of maximum-score and use this index to find out the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "\n",
    "import copy\n",
    "import time\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_losses = [0. for i in range(num_epochs)]\n",
    "    test_losses = [0. for i in range(num_epochs)]\n",
    "\n",
    "    train_accuracies = [0. for i in range(num_epochs)]\n",
    "    test_accuracies = [0. for i in range(num_epochs)]\n",
    "\n",
    "    label_acc_per_epoch = [[0] * num_epochs for i in range(10)]\n",
    "    label_val_per_epoch = [[0] * num_epochs for i in range(10)]\n",
    "\n",
    "    batch_loss = 0.0\n",
    "    \n",
    "    checkPoint = 1000;\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "\n",
    "        class_correct_train = list(0. for i in range(10))\n",
    "        class_total_train = list(0. for i in range(10))\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() \n",
    "            else:\n",
    "                model.eval() \n",
    "            \n",
    "            batch_loss = 0.0\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for j, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                correct_train_iter, total_train_iter = 0.0, 0.0\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    batch_loss += loss.item()\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    c = (preds == labels).squeeze()\n",
    "                    total_train_iter += labels.size(0)\n",
    "                    correct_train_iter += preds.eq(labels).sum().item()\n",
    "\n",
    "                    for i in range(len(labels)):\n",
    "                        label = labels[i]\n",
    "                        class_correct[label] += c[i].item()\n",
    "                        class_total[label] += 1\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        if j % checkPoint == checkPoint - 1 :\n",
    "                            train_acc_iter = correct_train_iter / total_train_iter\n",
    "                            train_loss_iter = batch_loss / checkPoint\n",
    "\n",
    "                            print('\\n[%d, %5d] loss: %.3f accuracy: %.3f' % (\n",
    "                            epoch + 1, j + 1, train_loss_iter, train_acc_iter))\n",
    "\n",
    "                            batch_loss = 0.0\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            if phase == 'train':\n",
    "                for i in range(10):\n",
    "                    acc = class_correct[i] / class_total[i]\n",
    "                    label_acc_per_epoch[i][epoch] = acc\n",
    "\n",
    "                train_losses[epoch] = epoch_loss\n",
    "                train_accuracies[epoch] = epoch_acc\n",
    "            else:\n",
    "                for i in range(10):\n",
    "                    acc = class_correct[i] / class_total[i]\n",
    "                    label_val_per_epoch[i][epoch] = acc\n",
    "\n",
    "                test_losses[epoch] = epoch_loss\n",
    "                test_accuracies[epoch] = epoch_acc\n",
    "\n",
    "            print('{} Loss: {:.3f} Acc: {:.3f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:3f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    history = {\n",
    "                \"train_losses\": train_losses,\n",
    "                \"train_accuracies\": train_accuracies,\n",
    "                \"test_losses\": train_losses,\n",
    "                \"test_accuracies\": train_accuracies,\n",
    "                \"label_acc_per_epoch\": label_acc_per_epoch,\n",
    "                \"label_val_per_epoch\": label_val_per_epoch\n",
    "              }\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Training and Validation Step\n",
    "---------\n",
    "\n",
    "- Define the neural network \n",
    "\n",
    "- Define a Loss function and optimizer\n",
    "\n",
    "Letâ€™s use a Classification Cross-Entropy loss and Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "scratch_model = Net() ## non-pretrained model\n",
    "\n",
    "## Inception v3 \n",
    "#scratch_model = models.inception_v3(pretrained=True, aux_logits=False)\n",
    "\n",
    "## VGG19\n",
    "#scratch_model = models.vgg19(pretrained='true')\n",
    "#scratch_model.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "print(scratch_model)\n",
    "\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(scratch_model.parameters(), lr=0.001)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "data_set = {'train': trainloader, 'val': testloader}\n",
    "model, history = train_model(scratch_model, data_set, scratch_criterion, scratch_optimizer, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing your network in PyTorch\n",
    "---------\n",
    "\n",
    "Let's plot the accuracy and loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(10.5, 7.5)\n",
    "plot_title = [\"train_accuracies\", \"train_losses\", \"test_accuracies\", \"test_losses\"]\n",
    "\n",
    "for i in range(4):\n",
    "    subplot = fig.add_subplot(2, 2, i+1)\n",
    "    subplot.set_xlim([-0.2, num_epochs])\n",
    "    subplot.set_ylim([0.0, 1 if i % 2 == 0 else max(history[plot_title[i]])+1])\n",
    "    subplot.set_title(plot_title[i])\n",
    "    subplot.plot(history[plot_title[i]], color = (\"red\" if i % 2 == 0 else \"blue\"))\n",
    "\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot train accuracy and validation accuracy for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,)\n",
    "fig.set_size_inches(10, 5.5)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    a = plt.plot(history[\"label_val_per_epoch\"][i], label='%s' % classes[i])\n",
    "\n",
    "plt.title(\"validation\")\n",
    "plt.ylabel('category')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "plt.ylim((0,1))\n",
    "plt.xlim((-0.3, num_epochs))\n",
    "plt.xticks(np.arange(0, num_epochs+1, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='lower center', ncol=5, frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,)\n",
    "fig.set_size_inches(10, 5.5)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    a = plt.plot(history[\"label_acc_per_epoch\"][i], label='%s' % classes[i])\n",
    "\n",
    "plt.title(\"Accuracy\")\n",
    "plt.ylabel('category')\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid(True)\n",
    "plt.ylim((0,1))\n",
    "plt.xlim((-0.3, num_epochs))\n",
    "plt.xticks(np.arange(0, num_epochs+1, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='lower center', ncol=5, frameon=False)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
